{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "anchor-section",
   "metadata": {},
   "source": [
    "# üìå Topic: Stemming\n",
    "\n",
    "### What you will learn\n",
    "- What stemming is and why it matters\n",
    "- How the Porter Stemmer algorithm works\n",
    "- How stemming reduces vocabulary size\n",
    "- Trade-offs between stemming and lemmatization\n",
    "- Real-world examples of word stemming\n",
    "\n",
    "### Why this matters\n",
    "Stemming is a crucial text normalization technique that reduces words to their root form. This further reduces vocabulary size, which improves model efficiency and generalizes word patterns. However, stemming is **lossy and rule-based**, so it sometimes produces non-words (\"stemm\" instead of \"stem\"). Understanding when to use stemming vs. lemmatization is essential for proper NLP preprocessing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "## What is Stemming?\n",
    "\n",
    "**Stemming** is the process of reducing words to their base or root form (called the \"stem\") by removing prefixes and suffixes.\n",
    "\n",
    "### Examples:\n",
    "- \"connecting\" ‚Üí \"connect\"\n",
    "- \"connected\" ‚Üí \"connect\"\n",
    "- \"connectivity\" ‚Üí \"connect\"\n",
    "- \"connects\" ‚Üí \"connect\"\n",
    "\n",
    "All these variations are treated as the same word, which:\n",
    "- **Reduces vocabulary size**: One stem instead of 4+ word forms\n",
    "- **Improves pattern recognition**: Models see more instances of the same concept\n",
    "- **Saves memory**: Smaller vocabulary = smaller models\n",
    "\n",
    "### Stemming vs. Lemmatization:\n",
    "\n",
    "| Aspect | Stemming | Lemmatization |\n",
    "|--------|----------|----------------|\n",
    "| **Method** | Rule-based (strip suffixes) | Dictionary-based (find root word) |\n",
    "| **Speed** | Fast | Slow |\n",
    "| **Accuracy** | May produce non-words | Always produces real words |\n",
    "| **\"running\"** | \"run\" | \"run\" |\n",
    "| **\"better\"** | \"better\" | \"good\" |\n",
    "| **Use case** | Search, document retrieval | NER, sentiment analysis |\n",
    "\n",
    "**Key insight**: Stemming is aggressive; lemmatization is intelligent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "porter-stemmer",
   "metadata": {},
   "source": [
    "## The Porter Stemmer Algorithm\n",
    "\n",
    "The **Porter Stemmer** is the most widely used stemming algorithm. It uses a series of **rewriting rules** to strip suffixes from English words.\n",
    "\n",
    "### How it works:\n",
    "1. Identifies the \"measure\" of a word (roughly, how many vowel-consonant pairs it has)\n",
    "2. Applies suffix-stripping rules based on the measure\n",
    "3. Returns the resulting stem\n",
    "\n",
    "### Example rule:\n",
    "```\n",
    "If measure > 0 and word ends in 'ed':\n",
    "    Remove 'ed'\n",
    "```\n",
    "\n",
    "This is why \"connected\" (measure > 0) ‚Üí \"connect\", but \"ped\" (measure = 0) is not modified.\n",
    "\n",
    "### Why Porter Stemmer?\n",
    "- Simple and fast (O(n) where n = word length)\n",
    "- Works well for English\n",
    "- Widely supported (NLTK, scikit-learn, etc.)\n",
    "- Good baseline before moving to lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e71eef6-0f77-4bac-8db7-4b79fcc9615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming reduces words to their base form by stripping suffixes\n",
    "# Example: \"running\", \"runs\", \"ran\" all become \"run\"\n",
    "# This is different from lemmatization, which uses a dictionary to find the actual root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73001ffd-ce8f-4979-a0d2-740e79fa9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Porter Stemmer from NLTK\n",
    "# PorterStemmer is an implementation of the famous Porter Stemming Algorithm\n",
    "# It's rule-based and doesn't use a dictionary\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-example",
   "metadata": {},
   "source": [
    "## Practical Example: Stemming a Word Family\n",
    "\n",
    "Let's see how the Porter Stemmer reduces all variations of the word \"connect\" to a single stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21615e85-1eaa-48a6-b29c-60f8f0648cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Porter Stemmer\n",
    "# This object has a .stem() method that reduces words to their stem\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Create a list of words that are all variations of \"connect\"\n",
    "# These have different suffixes: -ing, -ed, -ivity, -s\n",
    "connect_variations = [\"connecting\", \"connected\", \"connectivity\", \"connects\"]\n",
    "\n",
    "# Iterate through each word and stem it\n",
    "print(\"Porter Stemmer Output:\")\n",
    "print(\"=\" * 40)\n",
    "for word in connect_variations:\n",
    "    # ps.stem() removes suffix and returns the root\n",
    "    stem = ps.stem(word)\n",
    "    print(f\"{word:15} ‚Üí {stem}\")\n",
    "\n",
    "# Notice: All variations reduce to \"connect\"\n",
    "print(\"\\n‚úì Success: All word variants reduced to the same stem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "more-examples",
   "metadata": {},
   "source": [
    "## More Stemming Examples\n",
    "\n",
    "Let's see how the Porter Stemmer handles various English words and their common variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "more-examples-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test stemming on various word families\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Dictionary of word families for testing\n",
    "test_words = {\n",
    "    \"run\": [\"run\", \"running\", \"ran\", \"runs\"],\n",
    "    \"argue\": [\"argue\", \"argued\", \"arguing\", \"argument\"],\n",
    "    \"play\": [\"play\", \"playing\", \"played\", \"plays\"],\n",
    "    \"happy\": [\"happy\", \"happiness\", \"happily\"],\n",
    "}\n",
    "\n",
    "# Display stemming results\n",
    "for family, words in test_words.items():\n",
    "    print(f\"\\nWord family: {family}\")\n",
    "    print(\"-\" * 40)\n",
    "    stems = set()  # Use a set to see unique stems\n",
    "    for word in words:\n",
    "        stem = ps.stem(word)\n",
    "        stems.add(stem)\n",
    "        print(f\"  {word:15} ‚Üí {stem}\")\n",
    "    print(f\"  Unique stem(s): {stems}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edge-cases",
   "metadata": {},
   "source": [
    "## Edge Cases and Limitations\n",
    "\n",
    "The Porter Stemmer is rule-based, so it has limitations:\n",
    "\n",
    "### ‚ö†Ô∏è Problem 1: Over-stemming (too aggressive)\n",
    "```python\n",
    "\"universal\" ‚Üí \"univers\"\n",
    "\"university\" ‚Üí \"univers\"\n",
    "# These are different concepts but produce the same stem!\n",
    "```\n",
    "\n",
    "### ‚ö†Ô∏è Problem 2: Under-stemming (not aggressive enough)\n",
    "```python\n",
    "\"data\" ‚Üí \"data\" (not stemmed)\n",
    "\"datum\" ‚Üí \"datum\" (not stemmed)\n",
    "# Same concept, but different stems\n",
    "```\n",
    "\n",
    "### ‚ö†Ô∏è Problem 3: Non-words as output\n",
    "```python\n",
    "\"caresses\" ‚Üí \"caress\"\n",
    "\"ponies\" ‚Üí \"poni\"  # Not a real English word!\n",
    "```\n",
    "\n",
    "### ‚úÖ Solutions:\n",
    "- Use **lemmatization** if accuracy matters more than speed\n",
    "- Use **stemming** if processing large datasets where speed is critical\n",
    "- Combine with domain-specific dictionaries for specialized vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edge-cases-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate edge cases\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Edge case examples\n",
    "edge_cases = [\n",
    "    \"universal\",   # Over-stemming example\n",
    "    \"university\",  # Over-stemming example\n",
    "    \"data\",        # Under-stemming example\n",
    "    \"ponies\",      # Produces non-word\n",
    "    \"caresses\",    # Works fine\n",
    "]\n",
    "\n",
    "print(\"Edge Case Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "for word in edge_cases:\n",
    "    stem = ps.stem(word)\n",
    "    print(f\"{word:15} ‚Üí {stem}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Note: Some outputs aren't real English words!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "when-to-use",
   "metadata": {},
   "source": [
    "## When to Use Stemming\n",
    "\n",
    "### ‚úÖ Good use cases:\n",
    "1. **Search and retrieval**: User searches \"running\", finds documents with \"run\", \"runs\", etc.\n",
    "2. **Text classification**: Reducing vocabulary helps with sparse data\n",
    "3. **Information retrieval**: Web search engines use stemming\n",
    "4. **Fast preprocessing**: When you have billions of documents\n",
    "5. **Early-stage exploration**: Quick baseline before more sophisticated methods\n",
    "\n",
    "### ‚ùå Bad use cases:\n",
    "1. **Named Entity Recognition**: You need the original word form\n",
    "2. **Sentiment analysis**: Nuances matter (\"worse\" vs \"bad\")\n",
    "3. **Machine translation**: Word form carries grammatical meaning\n",
    "4. **Dense neural models**: Modern transformers handle morphology themselves\n",
    "\n",
    "### Rule of thumb:\n",
    "**Stemming works best for bag-of-words models and high-speed applications.** For neural networks and accurate NLP tasks, prefer lemmatization or skip normalization altogether."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-lemmatization",
   "metadata": {},
   "source": [
    "## Stemming vs. Lemmatization\n",
    "\n",
    "Let's compare with a preview of lemmatization (which we'll cover fully later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison between stemming and lemmatization\n",
    "# (Lemmatization requires spaCy, which we'll install later)\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "test_words = [\"better\", \"running\", \"arguing\", \"universal\"]\n",
    "\n",
    "print(\"Stemming vs. Lemmatization comparison:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Word':<15} | {'Stemmed':<15} | {'Notes':<20}\")\n",
    "print(\"-\" * 50)\n",
    "for word in test_words:\n",
    "    stem = ps.stem(word)\n",
    "    print(f\"{word:<15} | {stem:<15} | Stemmed\")\n",
    "\n",
    "print(\"\\nNote: Lemmatization (next notebook) produces smarter results\")\n",
    "print(\"Example: 'better' ‚Üí 'good' (lemmatization) vs 'better' (stemming)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key-takeaways",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Stemming reduces word variance**: Multiple word forms ‚Üí single stem\n",
    "2. **Porter Stemmer is rule-based and fast**: Good for large datasets\n",
    "3. **Trade-off: Speed vs. Accuracy**: Fast but may produce non-words or miss semantic differences\n",
    "4. **Over-stemming problem**: \"universal\" and \"university\" ‚Üí same stem\n",
    "5. **Know when to use it**: Search/retrieval systems, bag-of-words models\n",
    "6. **Know when NOT to use it**: NER, sentiment analysis, neural models\n",
    "\n",
    "## Next Steps:\n",
    "- Learn **lemmatization** (smarter, slower, dictionary-based)\n",
    "- Combine stemming with stopword removal for complete preprocessing\n",
    "- Experiment with different stemmers (Snowball, Lancaster) for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practice",
   "metadata": {},
   "source": [
    "## Practice Exercise\n",
    "\n",
    "Try stemming these words and see if you can identify:\n",
    "1. Words that stem correctly\n",
    "2. Over-stemming examples\n",
    "3. Under-stemming examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practice-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Stem this list and categorize the results\n",
    "practice_words = [\n",
    "    \"testing\", \"tested\", \"test\",\n",
    "    \"running\", \"runner\", \"runs\",\n",
    "    \"quickly\", \"quick\",\n",
    "    \"caresses\", \"ponies\", \"ties\"\n",
    "]\n",
    "\n",
    "ps = PorterStemmer()\n",
    "results = {}\n",
    "\n",
    "for word in practice_words:\n",
    "    stem = ps.stem(word)\n",
    "    if stem not in results:\n",
    "        results[stem] = []\n",
    "    results[stem].append(word)\n",
    "\n",
    "print(\"Words grouped by stem:\")\n",
    "print(\"=\" * 50)\n",
    "for stem, words in results.items():\n",
    "    print(f\"Stem '{stem}': {words}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "nlp_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
