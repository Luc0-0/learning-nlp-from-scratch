{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "anchor-section",
   "metadata": {},
   "source": [
    "# üìå Topic: Sentiment Analysis - Detecting Opinion & Emotion\n",
    "\n",
    "### What you will learn\n",
    "- What sentiment analysis is and how it works\n",
    "- Two approaches: lexicon-based (TextBlob, VADER) vs. neural (transformers)\n",
    "- Polarity (positive/negative) and subjectivity (opinion/fact)\n",
    "- Handling negations and complex sentence structures\n",
    "- When sentiment analysis works well and when it fails\n",
    "- Practical applications in customer feedback, social media monitoring\n",
    "\n",
    "### Why this matters\n",
    "Sentiment analysis automatically detects opinions and emotions in text. It powers review aggregation, brand monitoring, customer service automation, and social media insights. Understanding sentiment is crucial for any business analyzing customer feedback.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",\n",
   "metadata": {},\n",
   "source": [
    "## What is Sentiment Analysis?\n",
    "\n",
    "**Sentiment Analysis** is the task of determining the emotional tone or opinion expressed in text.\n",
    "\n",
    "### Example:\n",
    "```\n",
    "\"I loved the movie! The acting was fantastic.\" ‚Üí Positive\n",
    "\"The movie was okay, but the plot was confusing.\" ‚Üí Negative\n",
    "\"The movie will be released next Tuesday.\" ‚Üí Neutral (fact, no opinion)\n",
    "```\n",
    "\n",
    "### Two dimensions:\n",
    "\n",
    "1. **Polarity**: Is the opinion positive or negative?\n",
    "   - Range: -1.0 (very negative) to +1.0 (very positive)\n",
    "   - 0.0 = neutral\n",
    "\n",
    "2. **Subjectivity**: Is this an opinion or a fact?\n",
    "   - Range: 0.0 (objective fact) to 1.0 (subjective opinion)\n",
    "\n",
    "### Real-world applications:\n",
    "1. **Customer Reviews**: Amazon determines 5-star rating from text\n",
    "2. **Brand Monitoring**: Track what people think about your company online\n",
    "3. **Social Media**: Detect trending negative sentiment for crisis management\n",
    "4. **Customer Service**: Route angry customers to senior agents\n",
    "5. **Market Research**: Understand customer satisfaction from feedback\n",
    "6. **Content Recommendation**: Show users content they'll enjoy based on sentiment\n",
    "\n",
    "### Challenges:\n",
    "- **Sarcasm**: \"Oh great, another delayed flight\" (negative, but sounds positive)\n",
    "- **Negation**: \"I didn't hate it\" (double negative = positive?)\n",
    "- **Context**: \"The weather is killing me\" (negative context, but literally positive)\n",
    "- **Domain-specific**: \"bold design\" is positive for fashion, negative for medicine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "2643e291-1943-481b-9595-011386bfe8d2",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Sentiment analysis uses two main approaches:\n",
    "# 1. Lexicon-based: Look up words in a dictionary of known sentiments\n",
    "#    Fast, interpretable, but limited to known words\n",
    "# 2. Machine learning: Train a model on examples\n",
    "#    More accurate, but requires labeled data\n",
    "\n",
    "# In this notebook, we'll use TextBlob and VADER\n",
    "# Both are lexicon-based and don't require training"
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "test-sentences",\n",
   "metadata": {},\n",
   "source": [
    "## Test Sentences\n",
    "\n",
    "We'll use these sentences to understand how sentiment analysis handles different cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "a31c189d-03f3-4228-93a6-4d1edabc8740",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Test sentences covering different sentiment scenarios\n",
    "sent1 = \"I had a great time at the movie. It was really funny.\"  # Positive\n",
    "sent2 = \"I had a great time at the movie, but the parking was terrible\"  # Mixed sentiment\n",
    "sent3 = \"I had a great time at the movie, but the parking wasn't great\"  # Negation example\n",
    "sent4 = \"I went to see a movie\"  # Neutral (factual)\n",
    "\n",
    "test_sentences = [sent1, sent2, sent3, sent4]\n",
    "\n",
    "for i, sent in enumerate(test_sentences, 1):\n",
    "    print(f\"Sentence {i}: {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textblob",\n",
   "metadata": {},\n",
   "source": [
    "## Method 1: TextBlob - Simple Sentiment Analysis\n",
    "\n",
    "TextBlob uses pre-trained classifiers and provides polarity and subjectivity scores.\n",
    "\n",
    "### How it works:\n",
    "- Breaks text into words/phrases\n",
    "- Looks up sentiment scores from a trained lexicon\n",
    "- Averages scores for the entire sentence\n",
    "- Returns polarity (-1 to +1) and subjectivity (0 to 1)\n",
    "\n",
    "### Trade-offs:\n",
    "- ‚úÖ Simple and fast\n",
    "- ‚úÖ Works out-of-the-box\n",
    "- ‚ùå Limited to known words\n",
    "- ‚ùå Doesn't handle sarcasm well\n",
    "- ‚ùå Sentence-level analysis only (no emotion detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "100c2b11-b7dc-4948-b306-76e006ed74b7",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Import TextBlob for sentiment analysis\n",
    "# TextBlob: Simple, beginner-friendly sentiment analysis\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "textblob-analysis",\n",
   "metadata": {},\n",
   "outputs": [],\n",
    "source": [
    "# Analyze sentiment using TextBlob\n",
    "print(\"TextBlob Sentiment Analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Sentence':<40} | {'Polarity':<10} | {'Subjectivity':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for sent in test_sentences:\n",
    "    # Create TextBlob object and extract sentiment\n",
    "    blob = TextBlob(sent)\n",
    "    polarity = blob.sentiment.polarity  # Range: -1 (negative) to +1 (positive)\n",
    "    subjectivity = blob.sentiment.subjectivity  # Range: 0 (objective) to 1 (subjective)\n",
    "    \n",
    "    # Interpret results\n",
    "    if polarity > 0.1:\n",
    "        sentiment_label = \"Positive\"\n",
    "    elif polarity < -0.1:\n",
    "        sentiment_label = \"Negative\"\n",
    "    else:\n",
    "        sentiment_label = \"Neutral\"\n",
    "    \n",
    "    print(f\"{sent[:37]:<40} | {polarity:>8.3f} | {subjectivity:>11.3f}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  Polarity: Negative (-1) ‚Üê Neutral (0) ‚Üí Positive (+1)\")\n",
    "print(\"  Subjectivity: Objective (0) ‚Üê Mixed ‚Üí Subjective (1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vader",\n",
   "metadata": {},\n",
   "source": [
    "## Method 2: VADER - Optimized for Social Media\n",
    "\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is specifically tuned for social media text.\n",
    "\n",
    "### How it's different:\n",
    "- **Understands emojis and punctuation**: \"Great!!!\" is more positive than \"Great\"\n",
    "- **Handles ALL CAPS**: \"GREAT\" is more positive than \"great\"\n",
    "- **Social media aware**: Knows internet slang (\"lol\", \"omg\", etc.)\n",
    "- **Compound score**: Single score from -1 (negative) to +1 (positive)\n",
    "\n",
    "### When to use:\n",
    "- Twitter/social media analysis ‚úÖ\n",
    "- Product reviews ‚úÖ\n",
    "- Customer feedback ‚úÖ\n",
    "- Formal text ‚ùå (may misinterpret)\n",
    "- Sarcasm ‚ùå (still struggles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "vader-import",\n",
   "metadata": {},\n",
   "outputs": [],\n",
    "source": [
    "# Import VADER sentiment analyzer\n",
    "# VADER is optimized for social media and short texts\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# Download VADER lexicon (one-time download)\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER analyzer\n",
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "vader-analysis",\n",
   "metadata": {},\n",
   "outputs": [],\n",
    "source": [
    "# Analyze sentiment using VADER\n",
    "print(\"\\nVADER Sentiment Analysis\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Sentence':<40} | {'Compound Score':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for sent in test_sentences:\n",
    "    # Get VADER sentiment scores\n",
    "    scores = vader.polarity_scores(sent)\n",
    "    compound = scores['compound']  # Normalized score from -1 to +1\n",
    "    \n",
    "    # Interpret compound score\n",
    "    if compound >= 0.05:\n",
    "        sentiment_label = \"Positive\"\n",
    "    elif compound <= -0.05:\n",
    "        sentiment_label = \"Negative\"\n",
    "    else:\n",
    "        sentiment_label = \"Neutral\"\n",
    "    \n",
    "    print(f\"{sent[:37]:<40} | {compound:>8.3f} ({sentiment_label})\")\n",
    "    print(f\"  Details: Pos={scores['pos']:.3f}, Neg={scores['neg']:.3f}, Neu={scores['neu']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",\n",
   "metadata": {},\n",
   "source": [
    "## Comparing TextBlob vs. VADER\n",
    "\n",
    "Let's compare how these two methods differ on the same sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "comparison-code",\n",
   "metadata": {},\n",
   "outputs": [],\n",
    "source": [
    "# Side-by-side comparison\n",
    "import pandas as pd\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for sent in test_sentences:\n",
    "    # TextBlob scores\n",
    "    blob = TextBlob(sent)\n",
    "    tb_polarity = blob.sentiment.polarity\n",
    "    \n",
    "    # VADER scores\n",
    "    vader_scores = vader.polarity_scores(sent)\n",
    "    vader_compound = vader_scores['compound']\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Sentence': sent[:50],\n",
    "        'TextBlob': f\"{tb_polarity:.3f}\",\n",
    "        'VADER': f\"{vader_compound:.3f}\",\n",
    "        'Difference': f\"{abs(tb_polarity - vader_compound):.3f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nTextBlob vs. VADER Comparison\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° Key Observations:\")\n",
    "print(\"  - Both tend to agree on clearly positive/negative sentences\")\n",
    "print(\"  - They may differ on mixed or neutral sentences\")\n",
    "print(\"  - VADER may be better for social media language\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenge-cases",\n",
   "metadata": {},\n",
   "source": [
    "## Challenge Cases: Where Sentiment Analysis Fails\n",
    "\n",
    "Sentiment analysis struggles with these common language patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "challenge-cases-code",\n",
   "metadata": {},\n",
   "outputs": [],\n",
    "source": [
    "# Challenge test cases\n",
    "challenge_cases = [\n",
    "    (\"This movie is absolutely terrible!\", \"Negative\"),  # Emphatic negative\n",
    "    (\"Oh great, another delay.\", \"Negative\"),  # Sarcasm (sounds positive, but negative)\n",
    "    (\"I didn't hate it.\", \"Positive\"),  # Double negative = positive\n",
    "    (\"The book is not bad.\", \"Positive\"),  # Negation of negative\n",
    "    (\"This is sick!\", \"Positive\"),  # Slang (positive in modern context)\n",
    "    (\"I'm dying laughing!\", \"Positive\"),  # Hyperbole\n",
    "    (\"The phone is dead.\", \"Negative\"),  # Literal meaning, not sentiment\n",
    "    (\"This is fire!\", \"Positive\"),  # Slang (positive, but \"fire\" looks negative)\n",
    "]\n",
    "\n",
    "print(\"Challenge Cases for Sentiment Analysis\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Sentence':<35} | {'Expected':<10} | {'VADER':<10} | {'Correct?'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for text, expected_label in challenge_cases:\n",
    "    vader_scores = vader.polarity_scores(text)\n",
    "    compound = vader_scores['compound']\n",
    "    \n",
    "    # Classify VADER result\n",
    "    if compound >= 0.05:\n",
    "        vader_label = \"Positive\"\n",
    "    elif compound <= -0.05:\n",
    "        vader_label = \"Negative\"\n",
    "    else:\n",
    "        vader_label = \"Neutral\"\n",
    "    \n",
    "    # Check if correct\n",
    "    is_correct = \"‚úì\" if vader_label == expected_label else \"‚úó\"\n",
    "    \n",
    "    print(f\"{text:<35} | {expected_label:<10} | {compound:>8.3f} | {is_correct}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Common Failure Modes:\")\n",
    "print(\"1. Sarcasm: Hard for lexicon-based methods to detect\")\n",
    "print(\"2. Slang: New slang words not in lexicon\")\n",
    "print(\"3. Context: Same word different meaning in different domains\")\n",
    "print(\"4. Negation: Double negatives are tricky\")\n",
    "print(\"5. Domain-specific: Different industries use words differently\")"
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "best-practices",\n",
   "metadata": {},\n",
   "source": [
    "## Best Practices for Sentiment Analysis\n",
    "\n",
    "### ‚úÖ Do:\n",
    "1. **Preprocess text**: Remove URLs, normalize contractions (\"don't\" ‚Üí \"do not\")\n",
    "2. **Understand your data**: What sentiment patterns appear?\n",
    "3. **Set appropriate thresholds**: Don't use -0.05 to 0.05 as neutral if your data is mostly objective\n",
    "4. **Combine signals**: Use sentiment + entity information for better insights\n",
    "5. **Manual validation**: Spot-check results on sample data\n",
    "6. **Handle domain-specific**: Train custom models for specialized text\n",
    "\n",
    "### ‚ùå Don't:\n",
    "1. **Assume 100% accuracy**: Sentiment analysis makes mistakes\n",
    "2. **Use a single score**: Combine polarity + subjectivity + confidence\n",
    "3. **Ignore context**: \"I love how complicated this is\" (sarcasm)\n",
    "4. **Apply blindly**: Test on your actual data first\n",
    "5. **Treat as facts**: Sentiment scores are probabilities, not ground truth\n",
    "\n",
    "### When to use lexicon-based (TextBlob/VADER):\n",
    "- Quick prototyping and exploration\n",
    "- Real-time analysis (social media monitoring)\n",
    "- Limited computational resources\n",
    "\n",
    "### When to use machine learning (BERT, RoBERTa):\n",
    "- High accuracy required\n",
    "- Specialized domain (finance, medical)\n",
    "- Large labeled dataset available\n",
    "- Can afford training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "preprocessing",\n",
   "metadata": {},\n",
   "outputs": [],\n",
    "source": [
    "# Text preprocessing improves sentiment analysis\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Clean text for sentiment analysis.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Expand common contractions\n",
    "    contractions_dict = {\n",
    "        \"don't\": \"do not\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"aren't\": \"are not\"\n",
    "    }\n",
    "    \n",
    "    for contraction, expansion in contractions_dict.items():\n",
    "        text = text.replace(contraction, expansion)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test preprocessing\n",
    "raw_text = \"I don't like this product. Check out http://example.com for reviews\"\n",
    "cleaned_text = preprocess_text(raw_text)\n",
    "\n",
    "print(f\"Original: {raw_text}\")\n",
    "print(f\"Cleaned:  {cleaned_text}\")\n",
    "\n",
    "# Compare VADER scores\n",
    "print(f\"\\nSentiment (raw):     {vader.polarity_scores(raw_text)['compound']:.3f}\")\n",
    "print(f\"Sentiment (cleaned): {vader.polarity_scores(cleaned_text)['compound']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key-takeaways",\n",
   "metadata": {},\n",
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Sentiment Analysis detects opinion**: Polarity (positive/negative) and subjectivity\n",
    "2. **Two main approaches**: \n",
    "   - Lexicon-based (fast, simple, transparent) ‚Üê Use for quick analysis\n",
    "   - Machine learning (accurate, complex, opaque) ‚Üê Use for production\n",
    "3. **TextBlob is easy**: Good starting point for learning\n",
    "4. **VADER is better for social media**: Understands emojis, emphasis, slang\n",
    "5. **No perfect solution**: Sarcasm, slang, and context remain challenging\n",
    "6. **Always validate**: Test on your actual data before deploying\n",
    "7. **Preprocessing matters**: Cleaning text improves results\n",
    "\n",
    "## Next Steps:\n",
    "- Learn **transformers** (BERT, RoBERTa) for neural sentiment analysis\n",
    "- Build **aspect-based sentiment analysis** (\"Good screen, bad battery\")\n",
    "- Deploy **real-time social media monitoring**\n",
    "- Combine with **NER** for entity-specific sentiment"
   ]
  },\n",
   "cell_type": "markdown",\n",
   "id": "practice",\n",
   "metadata": {},\n",
   "source": [
    "## Practice Exercises\n",
    "\n",
    "Try these on your own:"
   ]
  },\n",
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "practice-1",\n",
   "metadata": {},\n",
   "outputs": [],\n",
    "source": [
    "# Exercise 1: Analyze sentiment of custom reviews\n",
    "custom_reviews = [\n",
    "    \"This product is amazing! Highly recommend.\",\n",
    "    \"Terrible quality. Broke after one day.\",\n",
    "    \"It's okay. Nothing special but does the job.\"\n",
    "]\n",
    "\n",
    "for review in custom_reviews:\n",
    "    vader_score = vader.polarity_scores(review)['compound']\n",
    "    blob = TextBlob(review)\n",
    "    textblob_score = blob.sentiment.polarity\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"  VADER:    {vader_score:.3f}\")\n",
    "    print(f\"  TextBlob: {textblob_score:.3f}\")\n",
    "    print()"
   ]
  },\n",
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "practice-2",\n",
   "metadata": {},\n",
   "outputs": [],\n",
    "source": [
    "# Exercise 2: Find the most positive and negative words\n",
    "sample_text = \"I absolutely love this restaurant! Great food, amazing service, wonderful atmosphere!\"\n",
    "doc = spacy.load(\"en_core_web_sm\")(sample_text.lower())\n",
    "\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(\"\\nPositive words found:\")\n",
    "positive_words = [\"love\", \"great\", \"amazing\", \"wonderful\", \"excellent\"]\n",
    "for word in positive_words:\n",
    "    if word in sample_text.lower():\n",
    "        print(f\"  - {word}\")"
   ]
  },\n",
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "practice-3",\n",
   "metadata": {},\n",
   "outputs": [],\n",
    "source": [
    "# Exercise 3: Batch sentiment analysis\n",
    "# Analyze multiple texts and create a summary\n",
    "tweets = [\n",
    "    \"Just got the new iPhone, absolutely love it!\",\n",
    "    \"Worst customer service ever. Never coming back.\",\n",
    "    \"The weather today is really nice.\",\n",
    "    \"Can't believe how much I enjoyed that movie!\"\n",
    "]\n",
    "\n",
    "sentiment_summary = []\n",
    "for tweet in tweets:\n",
    "    score = vader.polarity_scores(tweet)['compound']\n",
    "    if score > 0.1:\n",
    "        label = \"Positive\"\n",
    "    elif score < -0.1:\n",
    "        label = \"Negative\"\n",
    "    else:\n",
    "        label = \"Neutral\"\n",
    "    sentiment_summary.append((tweet, label, score))\n",
    "\n",
    "for tweet, label, score in sentiment_summary:\n",
    "    print(f\"[{label:8}] {score:>7.3f} - {tweet[:50]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "nlp_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexel": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
