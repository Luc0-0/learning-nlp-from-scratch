{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "anchor-section",
   "metadata": {},
   "source": [
    "# ðŸ“Œ Topic: Named Entity Recognition (NER) - Fundamentals\n",
    "\n",
    "### What you will learn\n",
    "1. **NER fundamentals** - What entities are and why they matter\n",
    "2. **Entity types** - PERSON, ORG, DATE, NORP, GPE, MONEY, PERCENT, and more\n",
    "3. **How NER models work** - Neural networks trained on annotated corpora\n",
    "4. **Extraction workflows** - Finding, classifying, and structuring entities\n",
    "5. **Visualization techniques** - Using spaCy's displacy to see extractions\n",
    "6. **Model limitations** - When and why NER fails on real text\n",
    "\n",
    "### Why this matters\n",
    "NER is the foundation for:\n",
    "- **Knowledge graphs**: Connecting people to organizations to locations\n",
    "- **Information extraction**: Populating databases from documents\n",
    "- **Question answering**: Understanding what questions are asking about\n",
    "- **Content search**: Finding articles about specific people/companies\n",
    "- **Content moderation**: Detecting sensitive information to redact\n",
    "- **Recommendation**: Linking articles via shared entities\n",
    "\n",
    "### Real-world context\n",
    "When you search for news about a person and get all relevant articles, that's NER. When a knowledge base knows that Apple Inc. and Steve Jobs are related, that came from NER. Understanding how NER works enables building these systems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "what-is-ner",\n",
   "metadata": {},\n",
   "source": [
    "## What is Named Entity Recognition (NER)?\n",
    "\n",
    "**Named Entity Recognition** is the task of identifying and classifying named entities (proper nouns) in text.\n",
    "\n",
    "### Example:\n",
    "```\n",
    "Text: \"Google was founded on September 4, 1998, by Larry Page and Sergey Brin.\"\n",
    "\n",
    "Entities found:\n",
    "- Google â†’ ORG (Organization)\n",
    "- September 4, 1998 â†’ DATE\n",
    "- Larry Page â†’ PERSON\n",
    "- Sergey Brin â†’ PERSON\n",
    "```\n",
    "\n",
    "### Why NER matters:\n",
    "\n",
    "1. **Information Extraction**: Find key entities to populate databases\n",
    "2. **Knowledge Graphs**: Build networks of entities and relationships\n",
    "3. **Question Answering**: \"Who is the CEO of Google?\" â†’ Find PERSON associated with Google\n",
    "4. **Text Understanding**: Identify what the text is about\n",
    "5. **Recommendation Systems**: Recommend content about extracted entities\n",
    "6. **Content Moderation**: Detect sensitive information (names, locations)\n",
    "\n",
    "### Common Entity Types:\n",
    "\n",
    "| Tag | Meaning | Examples |\n",
    "|-----|---------|----------|\n",
    "| **PERSON** | Person names | John Smith, Emma, Barack Obama |\n",
    "| **ORG** | Organization names | Google, Apple, MIT |\n",
    "| **GPE** | Geo-political entity (country, city) | France, New York, Beijing |\n",
    "| **NORP** | Nationality, religion, political group | American, Christian, Democrat |\n",
    "| **DATE** | Dates and time periods | September 4, 1998, Tuesday |\n",
    "| **TIME** | Times | 3 PM, noon, midnight |\n",
    "| **MONEY** | Monetary values | $5 million, â‚¬100 |\n",
    "| **PERCENT** | Percentages | 50%, about 1/3 |\n",
    "| **FACILITY** | Buildings, airports, landmarks | Empire State Building, JFK Airport |\n",
    "| **PRODUCT** | Named products | iPhone, Windows 10 |\n",
    "| **EVENT** | Named events | World War II, Thanksgiving |\n",
    "| **LAW** | Named documents | Magna Carta, Affordable Care Act |\n",
    "| **LANGUAGE** | Language names | English, Mandarin |\n",
    "\n",
    "### How NER works:\n",
    "Modern NER systems use **neural networks** trained on annotated corpora. spaCy's model was trained on:\n",
    "- News articles labeled with entities\n",
    "- Web text with entity annotations\n",
    "- Achieves ~90% F1 score on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "initial-explanation",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Named Entity Recognition (NER) is a powerful tool that automatically:\n",
    "# 1. Searches through text for entities (proper nouns, dates, money, etc.)\n",
    "# 2. Analyzes and classifies each entity by type\n",
    "# 3. Understands relationships between entities\n",
    "# This enables building structured datasets from unstructured text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "b68ef212-6167-484a-8309-25d03af763ca",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Import required libraries\n",
    "import spacy  # Modern NLP library with pre-trained NER models\n",
    "from spacy import displacy  # Visualization tool for entities\n",
    "import pandas as pd  # For organizing entities into structured data\n",
    "import re  # For text cleaning"
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "loading-model",\n",
   "metadata": {},\n",
   "source": [
    "## Step 1: Load spaCy NER Model\n",
    "\n",
    "spaCy comes with pre-trained models that already know how to recognize entities. We just need to load one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "5c4b49f6-f886-4513-8ef3-f4c52223e2fc",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Load the spaCy English model\n",
    "# This model includes: tokenization, POS tagging, NER, dependency parsing, and word vectors\n",
    "# The NER component was trained on news data and achieves ~90% accuracy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "print(\"âœ“ Model loaded successfully!\")\n",
    "print(f\"\\nPipeline components: {nlp.pipe_names}\")\n",
    "# Output: ['tok2vec', 'morphologizer', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']"
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "sample-text",\n",
   "metadata": {},\n",
   "source": [
    "## Step 2: Prepare Sample Text\n",
    "\n",
    "Let's use a text about Google's history, which contains many named entities (people, organizations, dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "5ca6ec5c-21f1-4140-b38a-8f083de1babd",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Sample text with multiple types of entities\n",
    "# This text contains: PERSON, ORG, DATE, PERCENT, NORP - good test case for NER\n",
    "google_text = (\n",
    "    \"Google was founded on September 4, 1998, by American computer scientists \"\n",
    "    \"Larry Page and Sergey Brin. Together, they own about 14% of its publicly listed shares \"\n",
    "    \"and control 56% of its stockholder voting power through super-voting stock. \"\n",
    "    \"The company went public via an initial public offering (IPO) in 2004. \"\n",
    "    \"In 2015, Google was reorganized as a wholly owned subsidiary of Alphabet Inc. \"\n",
    "    \"Google is Alphabet's largest subsidiary and is a holding company for Alphabet's \"\n",
    "    \"internet properties and interests. \"\n",
    "    \"Sundar Pichai was appointed CEO of Google on October 24, 2015, replacing Larry Page, \"\n",
    "    \"who became the CEO of Alphabet. \"\n",
    "    \"On December 3, 2019, Pichai also became the CEO of Alphabet.\"\n",
    ")\n",
    "\n",
    "print(\"Sample Text:\")\n",
    "print(google_text)"
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "process-text",\n",
   "metadata": {},\n",
   "source": [
    "## Step 3: Process Text with spaCy NER\n",
    "\n",
    "When we pass text through nlp(), the NER component automatically identifies all entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "fdd30949-f819-40a5-b469-831aea0a2504",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Process text with spaCy's NER pipeline\n",
    "# nlp() tokenizes, processes, and identifies all entities in one go\n",
    "# Returns a Doc object with .ents property containing identified entities\n",
    "spacy_doc = nlp(google_text)\n",
    "\n",
    "print(f\"âœ“ Text processed successfully!\")\n",
    "print(f\"Total tokens: {len(spacy_doc)}\")\n",
    "print(f\"Entities found: {len(spacy_doc.ents)}\")"
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "extract-entities",\n",
   "metadata": {},\n",
   "source": [
    "## Step 4: Extract and Display Entities\n",
    "\n",
    "Let's examine all the entities that were found, along with their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "4165b8ed-54f0-4e8e-9818-5aef4b02745c",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Print all entities and their types\n",
    "# spacy_doc.ents is a tuple of Span objects representing entities\n",
    "# Each entity has .text (the entity text) and .label_ (the entity type)\n",
    "\n",
    "print(\"All Entities Found:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Entity':<30} | {'Type':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for entity in spacy_doc.ents:\n",
    "    print(f\"{entity.text:<30} | {entity.label_:<10}\")\n",
    "\n",
    "# Insight: Notice 'Alphabet' appears twice with different labels (ORG and GPE)\n",
    "# This is context-dependent - NER isn't always 100% consistent"
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "entity-statistics",\n",
   "metadata": {},\n",
   "source": [
    "## Step 5: Entity Statistics\n",
    "\n",
    "Let's analyze the distribution of entity types to understand what the text is about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "entity-stats",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Organize entities by type to understand text composition\n",
    "from collections import Counter\n",
    "\n",
    "# Extract only the entity labels\n",
    "entity_labels = [entity.label_ for entity in spacy_doc.ents]\n",
    "\n",
    "# Count occurrences of each entity type\n",
    "entity_counts = Counter(entity_labels)\n",
    "\n",
    "print(\"Entity Type Distribution:\")\n",
    "print(\"=\" * 40)\n",
    "for label, count in entity_counts.most_common():\n",
    "    print(f\"{label:<10} â†’ {count:2} entities\")\n",
    "\n",
    "# Insight: DATE and PERSON are most common\n",
    "# This makes sense - text is about Google's timeline and founders"
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "entity-dataframe",\n",
   "metadata": {},\n",
   "source": [
    "## Step 6: Organize Entities in DataFrame\n",
    "\n",
    "For further analysis, let's convert entities into a structured DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "entity-dataframe-code",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Create a structured DataFrame from entities\n",
    "# This enables: filtering, sorting, searching, exporting to databases\n",
    "entities_df = pd.DataFrame([\n",
    "    {\n",
    "        \"entity_text\": entity.text,\n",
    "        \"entity_type\": entity.label_,\n",
    "        \"start_char\": entity.start_char,  # Position in text\n",
    "        \"end_char\": entity.end_char\n",
    "    }\n",
    "    for entity in spacy_doc.ents\n",
    "])\n",
    "\n",
    "print(\"Entities as Structured Data:\")\n",
    "print(entities_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nâœ“ Total entities: {len(entities_df)}\")\n",
    "print(f\"âœ“ Unique types: {entities_df['entity_type'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",\n",
   "metadata": {},\n",
   "source": [
    "## Step 7: Visualize Entities\n",
    "\n",
    "spaCy's `displacy` module visualizes entities with color-coding, making it easy to understand what was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "visualization-code",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# displacy.render() creates an HTML visualization of entities\n",
    "# Different entity types get different colors for easy identification\n",
    "# style='ent' highlights entities; style='dep' shows dependency parsing\n",
    "\n",
    "html = displacy.render(spacy_doc, style='ent', page=False)\n",
    "\n",
    "# Display the visualization (only works in Jupyter notebooks)\n",
    "from IPython.display import HTML, display\n",
    "display(HTML(html))\n",
    "\n",
    "print(\"\\nâœ“ Entity visualization generated!\")\n",
    "print(\"Color key:\")\n",
    "print(\"  Cyan: ORG (Organization)\")\n",
    "print(\"  Pink: PERSON\")\n",
    "print(\"  Light green: NORP (Nationality/Religion)\")\n",
    "print(\"  Light blue: DATE\")\n",
    "print(\"  Yellow: GPE (Geo-political)\")"
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "filtering-entities",\n",
   "metadata": {},\n",
   "source": [
    "## Step 8: Filter and Query Entities\n",
    "\n",
    "Now that we have entities organized, we can ask interesting questions about the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "filtering-code",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Example 1: Find all PERSON entities (people mentioned)\n",
    "people = entities_df[entities_df['entity_type'] == 'PERSON']['entity_text'].unique()\n",
    "print(f\"People mentioned in text ({len(people)}):\")\n",
    "for person in people:\n",
    "    print(f\"  - {person}\")\n",
    "\n",
    "# Example 2: Find all DATE entities (important dates)\n",
    "print(f\"\\nImportant dates ({len(entities_df[entities_df['entity_type'] == 'DATE'])}):\")\n",
    "dates = entities_df[entities_df['entity_type'] == 'DATE']['entity_text'].tolist()\n",
    "for date in dates:\n",
    "    print(f\"  - {date}\")\n",
    "\n",
    "# Example 3: Find all ORG entities (organizations)\n",
    "print(f\"\\nOrganizations mentioned:\")\n",
    "orgs = entities_df[entities_df['entity_type'] == 'ORG']['entity_text'].unique()\n",
    "for org in orgs:\n",
    "    print(f\"  - {org}\")"
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "limitations",\n",
   "metadata": {},\n",
   "source": [
    "## Step 9: Understanding NER Limitations\n",
    "\n",
    "Pre-trained NER models aren't perfect. Understanding their limitations is crucial for production systems."
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "limitations-detail",\n",
   "metadata": {},\n",
   "source": [
    "### Common NER Errors:\n",
    "\n",
    "#### âŒ **Problem 1: Multi-word entity splitting**\n",
    "```\n",
    "Text: \"Larry Page founded Google\"\n",
    "Issue: \"Larry\" and \"Page\" might be tagged separately\n",
    "Reality: Should be one PERSON entity \"Larry Page\"\n",
    "spaCy status: âœ“ Usually handles this correctly\n",
    "```\n",
    "\n",
    "#### âŒ **Problem 2: Ambiguous labels**\n",
    "```\n",
    "Text: \"He went to New York and then to Germany\"\n",
    "Issue: Both are places, but:\n",
    "- \"New York\" might be tagged as CITY, GPE, or LOCATION\n",
    "- \"Germany\" might be tagged as COUNTRY or GPE\n",
    "The model was trained on NEWS, so it prefers GPE\n",
    "```\n",
    "\n",
    "#### âŒ **Problem 3: Domain mismatch**\n",
    "```\n",
    "News domain: \"Barack Obama visited Israel\"\n",
    "Model works great (trained on news)\n",
    "\n",
    "Medical domain: \"Patient took aspirin after diagnosis\"\n",
    "Issue: \"aspirin\" should be MEDICINE, but model doesn't know this entity type\n",
    "Solution: Train custom NER for your domain\n",
    "```\n",
    "\n",
    "#### âŒ **Problem 4: Case sensitivity**\n",
    "```\n",
    "\"john smith\" vs. \"John Smith\"\n",
    "Lowercase version is harder to recognize as PERSON\n",
    "NER relies on capitalization cues\n",
    "```\n",
    "\n",
    "#### âŒ **Problem 5: Context-dependent entities**\n",
    "```\n",
    "\"Apple is a fruit\" â†’ 'fruit' type, not ORG\n",
    "\"I use Apple products\" â†’ ORG\n",
    "Context matters, and models sometimes get confused\n",
    "```\n",
    "\n",
    "### âœ… **How to handle limitations:**\n",
    "1. **Evaluate on your data**: F1 score might be 90% in general, but only 70% on your text type\n",
    "2. **Post-processing rules**: Fix known errors with regex or domain knowledge\n",
    "3. **Custom training**: Fine-tune models on domain-specific annotated data\n",
    "4. **Ensemble methods**: Combine multiple NER systems for better coverage\n",
    "5. **Human review**: Always have humans validate critical entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "id": "common-errors",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Common NER errors - test your understanding\n",
    "test_sentences = [\n",
    "    \"apple released the iphone\",  # Missing capitals - harder to recognize\n",
    "    \"I went to New York City on December 25\",  # Multi-word entity\n",
    "    \"Patient John Smith takes Aspirin daily\",  # Medical domain\n",
    "    \"The Nile river flows through Egypt\",  # Geographic relationships\n",
    "]\n",
    "\n",
    "print(\"Testing NER edge cases:\")\n",
    "print(\"=\" * 60)\n",
    "for sentence in test_sentences:\n",
    "    doc = nlp(sentence)\n",
    "    print(f\"\\nText: {sentence}\")\n",
    "    print(f\"Entities found: {[(ent.text, ent.label_) for ent in doc.ents]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "real-world-applications",\n",
   "metadata": {},\n",
   "source": [
    "## Real-World NER Applications\n",
    "\n",
    "### 1. **Resume Parsing**\n",
    "Extract PERSON (candidate name), ORG (companies worked for), DATE (employment dates)\n",
    "\n",
    "### 2. **News Summarization**\n",
    "Find key PERSON and ORG entities to auto-generate headlines\n",
    "```\n",
    "\"Apple CEO Tim Cook announced new product\"\n",
    "â†’ Summary: \"Tim Cook (CEO of Apple) announced new product\"\n",
    "```\n",
    "\n",
    "### 3. **Knowledge Graph Construction**\n",
    "Extract entities and build relationships:\n",
    "```\n",
    "\"Larry Page founded Google in 1998\"\n",
    "â†’ Node 1: Larry Page (PERSON)\n",
    "â†’ Node 2: Google (ORG)\n",
    "â†’ Edge: founded\n",
    "â†’ Date: 1998\n",
    "```\n",
    "\n",
    "### 4. **Information Extraction for Databases**\n",
    "```python\n",
    "# From unstructured text to structured database:\n",
    "\"John Smith from Apple presented at TechCon 2024\"\n",
    "â†’ Speaker: John Smith\n",
    "â†’ Company: Apple\n",
    "â†’ Conference: TechCon\n",
    "â†’ Date: 2024\n",
    "```\n",
    "\n",
    "### 5. **Named Entity Linking**\n",
    "Connect identified entities to knowledge bases (Wikipedia, DBpedia):\n",
    "```\n",
    "\"Apple\" (ORG) â†’ Wikipedia:Apple Inc.\n",
    "\"Steve Jobs\" (PERSON) â†’ Wikipedia:Steve Jobs\n",
    "```\n",
    "\n",
    "### 6. **Content Recommendation**\n",
    "Recommend articles about extracted entities to users interested in those topics"
   ]
  },
  {
   "cell_type": "markdown",\n",
   "id": "key-takeaways",\n",
   "metadata": {},\n",
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **NER automatically identifies proper nouns**: PERSON, ORG, DATE, PERCENT, etc.\n",
    "2. **spaCy makes NER easy**: Pre-trained model with one line of code\n",
    "3. **Entity types enable structured analysis**: Ask questions like \"Find all people\" or \"Find all dates\"\n",
    "4. **No system is perfect**: Even best models achieve ~90% accuracy\n",
    "5. **Domain mismatch hurts performance**: News-trained model struggles on medical/technical text\n",
    "6. **Visualization helps verification**: displacy shows what the model found\n",
    "7. **Post-processing can fix errors**: Combine NER with rules and domain knowledge\n",
    "8. **NER enables downstream tasks**: Knowledge graphs, recommendation, question answering\n",
    "\n",
    "## Next Steps:\n",
    "- Learn **entity linking** (connecting entities to Wikipedia/knowledge bases)\n",
    "- Study **custom NER training** (fine-tune for your domain)\n",
    "- Explore **relation extraction** (finding relationships between entities)\n",
    "- Build **knowledge graphs** from extracted entities"
   ]
  },\n",
   "cell_type": "markdown",\n",
   "id": "practice",\n",
   "metadata": {},\n",
   "source": [
    "## Practice Exercises\n",
    "\n",
    "Try these on your own:"
   ]
  },\n",
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "practice-1",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Exercise 1: Extract entities from a new text\n",
    "new_text = (\n",
    "    \"Elon Musk, the CEO of Tesla and SpaceX, was born in South Africa. \"\n",
    "    \"He moved to the United States in 1995 to attend Stanford University.\"\n",
    ")\n",
    "\n",
    "new_doc = nlp(new_text)\n",
    "print(\"Extracted entities:\")\n",
    "for ent in new_doc.ents:\n",
    "    print(f\"  {ent.text:30} â†’ {ent.label_}\")"
   ]
  },\n",
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "practice-2",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Exercise 2: Count entity types in the new text\n",
    "from collections import Counter\n",
    "\n",
    "ent_types = Counter([ent.label_ for ent in new_doc.ents])\n",
    "print(\"Entity type distribution:\")\n",
    "for label, count in ent_types.most_common():\n",
    "    print(f\"  {label}: {count}\")"
   ]
  },\n",
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "practice-3",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Exercise 3: Create a simple question-answering system\n",
    "# \"Who is the CEO of Tesla?\" â†’ Extract PERSON + ORG relationship\n",
    "\n",
    "def answer_who_questions(doc, org_name):\n",
    "    \"\"\"Find PERSON entities near an ORG entity\"\"\"\n",
    "    people = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\" and org_name.lower() in doc.text.lower():\n",
    "            people.append(ent.text)\n",
    "    return people\n",
    "\n",
    "people_at_tesla = answer_who_questions(new_doc, \"Tesla\")\n",
    "print(f\"People associated with Tesla: {people_at_tesla}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "nlp_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
